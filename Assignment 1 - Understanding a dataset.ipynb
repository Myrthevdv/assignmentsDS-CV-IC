{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa4d751-50e2-46dc-9c30-cce3324f6844",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "Note: This notebook file for the assignment has deviations from the course guide with respect to the structure, sentence framing, question framing and numbering. Please consider this notebook file structure as the final structure and follow this.\n",
    "\n",
    "In this assignment, you will explore the CIFAR10 dataset. \n",
    "\n",
    "You have to download the dataset from Pytorch.\n",
    "\n",
    "Comment your code and indicate what the different instructions are doing and what you are showing and printing. \n",
    "When printing figures do not forget about the title, x and y labels. The font size should be matching the text size of the text in your report. \n",
    "Do not forget to add legends to the plots. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913b3d5a-e470-4d83-b845-1d304e61ea1c",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b91fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the needed packages for this assignment here\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e71845",
   "metadata": {},
   "source": [
    "#### Exercise 1.1 - Load data\n",
    "\n",
    "**a)** Load the CIFAR10 dataset. \n",
    "\n",
    "**b)** Print the number of samples and the number of classes present in the dataset. \n",
    "\n",
    "**c)** Also print the shape of an image in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9da0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex.1.1a,b & c\n",
    "import torchvision\n",
    "\n",
    "dataset = torchvision.datasets. ... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff3925c",
   "metadata": {},
   "source": [
    "#### Exercise 1.2 - Quantify dataset\n",
    "\n",
    "**a)** Print the number of samples per category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aa6ba5-bfee-4b03-ab71-ffe4b648c5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex.1.2a your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9bccd0-c0ee-4fb1-b708-b8fe1ae7a3a4",
   "metadata": {},
   "source": [
    "**b)** Plot the number of samples per category using a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fd7fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex.1.2b your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8770cb-2f62-45c7-ba41-273765184bb0",
   "metadata": {},
   "source": [
    "**Reflection: Answer the below question**\n",
    "\n",
    "Are you working with a balanced or an unbalanced dataset? Are there majoritarian classes? Do you think this will affect the later analysis and training of your models?\n",
    "\n",
    "> Your Answer (Double click to edit): "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab7d688",
   "metadata": {},
   "source": [
    "#### Exercise 1.3 - Visualize images in your dataset\n",
    "\n",
    "Create a figure with n x 4 sub-plots. The value of 'n' depends on the number of categories present in the dataset.\n",
    "As the title of each row in your figure, indicate the category it belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbe15647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex.1.3 your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ac727d",
   "metadata": {},
   "source": [
    "#### Exercise 1.4 - RGB feature extraction\n",
    "\n",
    "Extract RGB values from each image in your dataset as three seperate lists(one per channel). Each list should have 8 values. To do so, you can compute the histogram of each channel with 8 bins. Then you have to concatenate the values of all the three channels together resulting in a feature vector of size 24. This feature vector is the descriptor of an image in your dataset. You will have to do this for all the images present in your dataset in order to get the overall RGB descriptor which will be of size (n,24). Here 'n' depends on the number of samples present in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e7045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex.1.4 your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9135cb-7471-40c0-829a-d07f4aef6591",
   "metadata": {},
   "source": [
    "#### Exercise 1.5 - Compute the inter-class variability of your dataset.\n",
    "\n",
    "Inter-class correlation aims at understanding the relationship/correlation among the classes/categories present in your dataset. For this, you could compute a measure (for example mean, std etc.) collectively for all the samples belonging to each and every class of the dataset. Then you could make use of this measure to find the correlation among the classes/categories using the standard pandas dataframe correlation function. Link: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894d957a-b536-4f3a-8313-9662edb0f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex.1.5 your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d265983",
   "metadata": {},
   "source": [
    "**c)** Compute the Silhouette score. \n",
    "\n",
    "The Silhouette score is used to assess the performance of using unsupervised machine learning (clustering). We can also use it here to assess the compactness of the extracted descriptors per category and for the group of categories as their mean.\n",
    "\n",
    "You can use the function available in Sklearn - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f631479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex.1.5c your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c34c1",
   "metadata": {},
   "source": [
    "**Reflection: (Answer the below questions)** \n",
    "\n",
    "**1.** Does Intra-class correlation score/coefficient help you assess the degree of similarity among the samples of a category?\n",
    "> Your Answer (Double click to edit): \n",
    "\n",
    "**2.** What can you deduce from the Inter-class correlation and Silhouette score?\n",
    "> Your Answer (Double click to edit): "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd728d06",
   "metadata": {},
   "source": [
    "#### Exercise 1.6 - Dimensionality reduction for visualization \n",
    "\n",
    "We can visualize large datasets having higher dimensions or features in 2- or 3-dimensional spaces. For this, you need to reduce the dimensionality of the data. \n",
    "\n",
    "In this exercise, you are asked to use PCA for reducing dimensionality.\n",
    "\n",
    "Link to function to apply PCA: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "\n",
    "Create the following two figures:\n",
    "\n",
    "**a)** Rely on the first 2 principal components to plot the samples of your dataset. Use one color per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b79009c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex.1.6a your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a3b6f1-1fb1-4c0d-af96-415e887fccc6",
   "metadata": {},
   "source": [
    "**b)** Rely on the first 3 principal components to create a 3D plot. Use one color per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d117388e-ab4b-4d51-b16f-31f8e0b0a7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex.1.6b your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7061bd12",
   "metadata": {},
   "source": [
    "#### Exercise 1.7 - Reflection\n",
    "\n",
    "Reflect on the following questions.\n",
    "\n",
    "**a)** Will you obtain the same visualisation in the feature space for different extracted features?\n",
    "> Your Answer (Double click to edit): \n",
    "    \n",
    "**b)** Are the classes distinguishable on the feature space when relying on PCA over RGB?\n",
    "> Your Answer (Double click to edit): \n",
    "    \n",
    "**c)** What other visualization could you include to better describe your data?\n",
    "> Your Answer (Double click to edit): "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d051c7a1",
   "metadata": {},
   "source": [
    "#### [Optional] Exercise: Repeat experiments with different image descriptors\n",
    "\n",
    "e.g. \n",
    "- Harris Corner Detection\n",
    "\n",
    "- Shi-Tomasi Corner Detector and Good Features to Track\n",
    "\n",
    "- Scale-Invariant Feature Transform (SIFT)\n",
    "\n",
    "- Speeded-up robust features (SURF)\n",
    "\n",
    "- Features from Accelerated Segment Test (FAST)\n",
    "\n",
    "- Blob Detectors With LoG, DoG, and DoH\n",
    "\n",
    "If you have OpenCV installed you can follow this example,\n",
    "https://automaticaddison.com/image-feature-detection-description-and-matching-in-opencv/\n",
    "\n",
    "When using Scikit-image,\n",
    "https://scikit-image.org/docs/dev/api/skimage.feature.html?highlight=hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ef8486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
